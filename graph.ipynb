{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_DVkteRVmfJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.addPyFile(\"/csproject/msbd5003/jars/graphframes-0.8.2-spark3.0-s_2.12.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphframes\n",
      "  Using cached graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy in /Users/tianjiaohe/Conda/lib/python3.9/site-packages (from graphframes) (1.21.5)\n",
      "Requirement already satisfied: nose in /Users/tianjiaohe/Conda/lib/python3.9/site-packages (from graphframes) (1.3.7)\n",
      "Installing collected packages: graphframes\n",
      "Successfully installed graphframes-0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PqBXqXd0VmfM"
   },
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K7j0wLcnVmfN",
    "outputId": "2b7d587d-f59a-4178-f60f-335e7b2ca33b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianjiaohe/spark/spark-3.3.1-bin-hadoop2/python/pyspark/sql/dataframe.py:148: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  a|  Alice| 34|\n",
      "|  b|    Bob| 36|\n",
      "|  c|Charlie| 37|\n",
      "|  d|  David| 29|\n",
      "|  e| Esther| 32|\n",
      "|  f|  Fanny| 38|\n",
      "|  g|  Gabby| 60|\n",
      "+---+-------+---+\n",
      "\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  a|  b|      friend|\n",
      "|  b|  c|      follow|\n",
      "|  c|  b|      follow|\n",
      "|  f|  c|      follow|\n",
      "|  e|  f|      follow|\n",
      "|  e|  d|      friend|\n",
      "|  d|  a|      friend|\n",
      "|  a|  e|      friend|\n",
      "|  g|  e|      follow|\n",
      "+---+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vertics DataFrame\n",
    "v = spark.createDataFrame([\n",
    "  (\"a\", \"Alice\", 34),\n",
    "  (\"b\", \"Bob\", 36),\n",
    "  (\"c\", \"Charlie\", 37),\n",
    "  (\"d\", \"David\", 29),\n",
    "  (\"e\", \"Esther\", 32),\n",
    "  (\"f\", \"Fanny\", 38),\n",
    "  (\"g\", \"Gabby\", 60)\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "# Edges DataFrame(directed edges)\n",
    "e = spark.createDataFrame([\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "  (\"f\", \"c\", \"follow\"),\n",
    "  (\"e\", \"f\", \"follow\"),\n",
    "  (\"e\", \"d\", \"friend\"),\n",
    "  (\"d\", \"a\", \"friend\"),\n",
    "  (\"a\", \"e\", \"friend\"),\n",
    "  (\"g\", \"e\", \"follow\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v, e)\n",
    "\n",
    "g.vertices.show()\n",
    "g.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id|count|\n",
      "+---+-----+\n",
      "|  c|    2|\n",
      "|  b|    1|\n",
      "|  f|    1|\n",
      "|  e|    1|\n",
      "+---+-----+\n",
      "\n",
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|Charlie|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myInDegrees = g.edges.filter(\"relationship='follow'\").groupBy('dst').count()\\\n",
    "    .withColumnRenamed('dst', 'id')\n",
    "myInDegrees.show()\n",
    "myInDegrees.join(g.vertices,on = 'id').filter(\"count>=2\").select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8YYtm54fVmfO",
    "outputId": "1eecf2e0-b948-488a-9e28-f4eb58c18329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  a|  b|      friend|\n",
      "|  a|  e|      friend|\n",
      "+---+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# g.vertices and g.edges are just DataFrames\n",
    "# You can use any DataFrame API on them\n",
    "\n",
    "g.edges.filter(\"src = 'a'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3qiNVvHVmfO",
    "outputId": "3528c4cd-9b4a-4e8e-986f-51bbf6783255"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edges.filter(\"src = 'a'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Ag3K8zmgVmfP",
    "outputId": "74955628-60ce-4b94-9ade-2bb3f14a1b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  b|  c|      follow|\n",
      "|  f|  c|      follow|\n",
      "+---+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of followers of c.\n",
    "# This queries the edge DataFrame.\n",
    "print(g.edges.filter(\"relationship = 'follow' and dst = 'c'\").count())\n",
    "g.edges.filter(\"relationship = 'follow' and dst = 'c'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  b|  c|      follow|\n",
      "|  f|  c|      follow|\n",
      "+---+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.edges.filter(\"relationship = 'follow' and dst = 'c'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZA4ff0bIVmfP",
    "outputId": "90d3e1d2-791b-4665-f77c-f052674f42da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|outDegree|\n",
      "+---+---------+\n",
      "|  g|        1|\n",
      "|  f|        1|\n",
      "|  e|        2|\n",
      "|  d|        1|\n",
      "|  c|        1|\n",
      "|  b|        1|\n",
      "|  a|        2|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A GraphFrame has additional attributes\n",
    "\n",
    "g.outDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "n_S9gEQuVmfP",
    "outputId": "eb02f76d-82f2-4a5a-bbd2-f755ef9a2e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|  b|       2|\n",
      "|  c|       2|\n",
      "|  f|       1|\n",
      "|  d|       1|\n",
      "|  a|       1|\n",
      "|  e|       2|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.inDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z03dOzATVmfQ",
    "outputId": "7d3c204c-60bb-4269-eae8-24eb531586ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[dst#45], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(dst#45, 200), true, [id=#171]\n",
      "   +- *(1) HashAggregate(keys=[dst#45], functions=[partial_count(1)])\n",
      "      +- *(1) Project [dst#45]\n",
      "         +- *(1) Scan ExistingRDD[src#44,dst#45,relationship#46]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.inDegrees.explain()#doesn't show node with indegree of 0; since it use group by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|Charlie|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find all people who are being followed by at least 2 people.\n",
    "myInDegrees = g.edges.filter(\"relationship='follow'\").groupBy('dst').count()\\\n",
    "    .withColumnRenamed('dst', 'id')\n",
    "myInDegrees.join(g.vertices,on = 'id').filter(\"count>=2\").select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4h0p2GIPVmfQ",
    "outputId": "ed05d0e1-d0a9-45ff-b7be-aec507e1043f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|  f|       1|\n",
      "|  e|       2|\n",
      "|  d|       1|\n",
      "|  c|       2|\n",
      "|  b|       2|\n",
      "|  a|       1|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myInDegrees = g.edges.groupBy('dst').count()\\\n",
    "               .withColumnRenamed('dst', 'id').withColumnRenamed('count', 'inDegree')\n",
    "myInDegrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrwFwbySVmfR",
    "outputId": "86467ef7-9893-499c-8256-c4cd9f12ec58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[dst#45], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(dst#45, 200), true, [id=#218]\n",
      "   +- *(1) HashAggregate(keys=[dst#45], functions=[partial_count(1)])\n",
      "      +- *(1) Project [dst#45]\n",
      "         +- *(1) Scan ExistingRDD[src#44,dst#45,relationship#46]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myInDegrees.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvcpJspQVmfR",
    "outputId": "8504a893-2d6c-421b-c5b7-8272b436163c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized 1x Replicated\n"
     ]
    }
   ],
   "source": [
    "print(g.inDegrees.storageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXbCQ9FTVmfR",
    "outputId": "8ccbfd47-cf22-4afa-e4cf-063add44e311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, inDegree: int]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.inDegrees.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hA7m_OoiVmfR",
    "outputId": "57972366-6daa-4572-bc45-708cfc4f6f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disk Memory Deserialized 1x Replicated\n"
     ]
    }
   ],
   "source": [
    "print(g.inDegrees.storageLevel)#store it in memory, if not enough, store it in disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8651lnCVmfS",
    "outputId": "d2664cf6-0231-493d-dcca-93805b6588b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized 1x Replicated\n"
     ]
    }
   ],
   "source": [
    "print(g.vertices.storageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHDK_UACVmfS",
    "outputId": "0b428bc1-28d4-4639-a527-35e31f82ffb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphFrame(v:[id: string, name: string ... 1 more field], e:[src: string, dst: string ... 1 more field])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.cache()#build this thing in a modular way, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RevChQZ6VmfS",
    "outputId": "b543fde9-30d4-4e16-815b-b768bd52fdbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disk Memory Deserialized 1x Replicated\n",
      "Disk Memory Deserialized 1x Replicated\n"
     ]
    }
   ],
   "source": [
    "print(g.vertices.storageLevel)\n",
    "print(g.edges.storageLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPvszy7SVmfS",
    "outputId": "2d5dc980-3984-4315-d650-6bbcf340a475"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/csproject/msbd5003/python/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------------+\n",
      "|             src|          edge|             dst|\n",
      "+----------------+--------------+----------------+\n",
      "|  {d, David, 29}|{d, a, friend}|  {a, Alice, 34}|\n",
      "|{c, Charlie, 37}|{c, b, follow}|    {b, Bob, 36}|\n",
      "|  {a, Alice, 34}|{a, b, friend}|    {b, Bob, 36}|\n",
      "|  {f, Fanny, 38}|{f, c, follow}|{c, Charlie, 37}|\n",
      "|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 37}|\n",
      "| {e, Esther, 32}|{e, d, friend}|  {d, David, 29}|\n",
      "|  {g, Gabby, 60}|{g, e, follow}| {e, Esther, 32}|\n",
      "|  {a, Alice, 34}|{a, e, friend}| {e, Esther, 32}|\n",
      "| {e, Esther, 32}|{e, f, follow}|  {f, Fanny, 38}|\n",
      "+----------------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A triplet view of the graph\n",
    "\n",
    "g.triplets.show() #complete picture for graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQCWcgAQVmfS",
    "outputId": "1d195815-6f7c-4bc2-9770-8c801d00e5ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [src#53, edge#51, dst#55]\n",
      "   +- SortMergeJoin [edge#51.dst], [dst#55.id], Inner\n",
      "      :- Sort [edge#51.dst ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(edge#51.dst, 200), ENSURE_REQUIREMENTS, [plan_id=342]\n",
      "      :     +- SortMergeJoin [edge#51.src], [src#53.id], Inner\n",
      "      :        :- Sort [edge#51.src ASC NULLS FIRST], false, 0\n",
      "      :        :  +- Exchange hashpartitioning(edge#51.src, 200), ENSURE_REQUIREMENTS, [plan_id=335]\n",
      "      :        :     +- Project [struct(src, src#6, dst, dst#7, relationship, relationship#8) AS edge#51]\n",
      "      :        :        +- Filter (isnotnull(src#6) AND isnotnull(dst#7))\n",
      "      :        :           +- Scan ExistingRDD[src#6,dst#7,relationship#8]\n",
      "      :        +- Sort [src#53.id ASC NULLS FIRST], false, 0\n",
      "      :           +- Exchange hashpartitioning(src#53.id, 200), ENSURE_REQUIREMENTS, [plan_id=336]\n",
      "      :              +- Project [struct(id, id#0, name, name#1, age, age#2L) AS src#53]\n",
      "      :                 +- Filter isnotnull(id#0)\n",
      "      :                    +- Scan ExistingRDD[id#0,name#1,age#2L]\n",
      "      +- Sort [dst#55.id ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(dst#55.id, 200), ENSURE_REQUIREMENTS, [plan_id=343]\n",
      "            +- Project [struct(id, id#65, name, name#66, age, age#67L) AS dst#55]\n",
      "               +- Filter isnotnull(id#65)\n",
      "                  +- Scan ExistingRDD[id#65,name#66,age#67L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.triplets.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEt12di2VmfT"
   },
   "source": [
    "### Motif Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BGpu6fBBVmfU",
    "outputId": "a2a5f9b3-1d3a-40e5-c8f9-c035a1fb24df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianjiaohe/spark/spark-3.3.1-bin-hadoop2/python/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|           a|               b|\n",
      "+------------+----------------+\n",
      "|{b, Bob, 36}|{c, Charlie, 37}|\n",
      "+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#the most powerful technique\n",
    "# Search for pairs of vertices with edges in both directions between them.\n",
    "motifs = g.find(\"(a)-[]->(b); (b)-[]->(a)\").filter('a.id < b.id')#omit variable inside [] same edge in diff direction\n",
    "motifs.show()\n",
    "#vertex can be same for defining src and dst, every edge in the pattern should be diff\n",
    "# can use edge variable to represent edges in between,need to use diff variable to represent diff edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ABdw0FZgVmfU",
    "outputId": "4550ef28-174d-42c6-e723-735b1d41c7b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+--------------+\n",
      "|             a|              b|             c|\n",
      "+--------------+---------------+--------------+\n",
      "|{a, Alice, 34}|{e, Esther, 32}|{d, David, 29}|\n",
      "+--------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find triangles\n",
    "triangles = g.find(\"(a)-[]->(b); (b)-[]->(c); (c)-[]->(a)\")#two joins finding a triangles a->b->c(src)\n",
    "triangles = triangles.filter(\"a.id < b.id AND a.id < c.id\")#\n",
    "triangles.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|Charlie|\n",
      "|  David|\n",
      "|  Fanny|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[]->(b);(b)-[]->(c)\").filter(\"a.name=='Alice'\").select('c.name').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVqdMTg7VmfU",
    "outputId": "2e2564aa-c347-48ed-f85b-dd48616a7b21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(6) Project [a#630, b#632, c#657]\n",
      "+- *(6) BroadcastHashJoin [c#657.id, a#630.id], [__tmp-6526019406657860729#687.src, __tmp-6526019406657860729#687.dst], Inner, BuildRight\n",
      "   :- *(6) Project [a#630, b#632, c#657]\n",
      "   :  +- *(6) BroadcastHashJoin [__tmp-430217833014886237#655.dst], [c#657.id], Inner, BuildRight, (a#630.id < c#657.id)\n",
      "   :     :- *(6) BroadcastHashJoin [b#632.id], [__tmp-430217833014886237#655.src], Inner, BuildRight\n",
      "   :     :  :- *(6) Project [a#630, b#632]\n",
      "   :     :  :  +- *(6) BroadcastHashJoin [__tmp-1043886091038848698#628.dst], [b#632.id], Inner, BuildRight, (a#630.id < b#632.id)\n",
      "   :     :  :     :- *(6) BroadcastHashJoin [__tmp-1043886091038848698#628.src], [a#630.id], Inner, BuildRight\n",
      "   :     :  :     :  :- *(6) Project [struct(src, src#44, dst, dst#45, relationship, relationship#46) AS __tmp-1043886091038848698#628]\n",
      "   :     :  :     :  :  +- InMemoryTableScan [dst#45, relationship#46, src#44]\n",
      "   :     :  :     :  :        +- InMemoryRelation [src#44, dst#45, relationship#46], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :     :  :     :  :              +- *(1) Scan ExistingRDD[src#44,dst#45,relationship#46]\n",
      "   :     :  :     :  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<id:string,name:string,age:bigint>, false].id)), [id=#628]\n",
      "   :     :  :     :     +- *(1) Project [struct(id, id#38, name, name#39, age, age#40L) AS a#630]\n",
      "   :     :  :     :        +- InMemoryTableScan [age#40L, id#38, name#39]\n",
      "   :     :  :     :              +- InMemoryRelation [id#38, name#39, age#40L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :     :  :     :                    +- *(1) Scan ExistingRDD[id#38,name#39,age#40L]\n",
      "   :     :  :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<id:string,name:string,age:bigint>, false].id)), [id=#634]\n",
      "   :     :  :        +- *(2) Project [struct(id, id#38, name, name#39, age, age#40L) AS b#632]\n",
      "   :     :  :           +- InMemoryTableScan [age#40L, id#38, name#39]\n",
      "   :     :  :                 +- InMemoryRelation [id#38, name#39, age#40L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :     :  :                       +- *(1) Scan ExistingRDD[id#38,name#39,age#40L]\n",
      "   :     :  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<src:string,dst:string,relationship:string>, false].src)), [id=#641]\n",
      "   :     :     +- *(3) Project [struct(src, src#44, dst, dst#45, relationship, relationship#46) AS __tmp-430217833014886237#655]\n",
      "   :     :        +- InMemoryTableScan [dst#45, relationship#46, src#44]\n",
      "   :     :              +- InMemoryRelation [src#44, dst#45, relationship#46], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :     :                    +- *(1) Scan ExistingRDD[src#44,dst#45,relationship#46]\n",
      "   :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<id:string,name:string,age:bigint>, false].id)), [id=#647]\n",
      "   :        +- *(4) Project [struct(id, id#38, name, name#39, age, age#40L) AS c#657]\n",
      "   :           +- InMemoryTableScan [age#40L, id#38, name#39]\n",
      "   :                 +- InMemoryRelation [id#38, name#39, age#40L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :                       +- *(1) Scan ExistingRDD[id#38,name#39,age#40L]\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<src:string,dst:string,relationship:string>, false].src, input[0, struct<src:string,dst:string,relationship:string>, false].dst)), [id=#654]\n",
      "      +- *(5) Project [struct(src, src#44, dst, dst#45, relationship, relationship#46) AS __tmp-6526019406657860729#687]\n",
      "         +- InMemoryTableScan [dst#45, relationship#46, src#44]\n",
      "               +- InMemoryRelation [src#44, dst#45, relationship#46], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     +- *(1) Scan ExistingRDD[src#44,dst#45,relationship#46]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "triangles.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXX0veY9VmfU",
    "outputId": "a243196f-9a2a-4332-e815-edb5387720da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+\n",
      "|              a|               b|\n",
      "+---------------+----------------+\n",
      "| {a, Alice, 34}| {e, Esther, 32}|\n",
      "|{e, Esther, 32}|  {d, David, 29}|\n",
      "| {a, Alice, 34}|    {b, Bob, 36}|\n",
      "| {g, Gabby, 60}| {e, Esther, 32}|\n",
      "|{e, Esther, 32}|  {f, Fanny, 38}|\n",
      "| {f, Fanny, 38}|{c, Charlie, 37}|\n",
      "| {d, David, 29}|  {a, Alice, 34}|\n",
      "+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Negation(anti join)\n",
    "oneway = g.find(\"(a)-[]->(b); !(b)-[]->(a)\")\n",
    "oneway.show()#only having edges from a to b, without edges from b to a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|  Fanny|\n",
      "|Charlie|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[]->(b);(b)-[]->(c);!(c)-[]->(a)\").filter(\"a.name=='Alice'\").select('c.name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDoU_5VbVmfU",
    "outputId": "cdd1b5f6-a38d-4962-f9c6-cb136f44ca6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[a#361, b#363], functions=[])\n",
      "   +- Exchange hashpartitioning(a#361, b#363, 200), ENSURE_REQUIREMENTS, [plan_id=5226]\n",
      "      +- HashAggregate(keys=[a#361, b#363], functions=[])\n",
      "         +- SortMergeJoin [coalesce(a#361, [,,0]), isnull(a#361), coalesce(b#363, [,,0]), isnull(b#363)], [coalesce(a#410, [,,0]), isnull(a#410), coalesce(b#411, [,,0]), isnull(b#411)], LeftAnti\n",
      "            :- Sort [coalesce(a#361, [,,0]) ASC NULLS FIRST, isnull(a#361) ASC NULLS FIRST, coalesce(b#363, [,,0]) ASC NULLS FIRST, isnull(b#363) ASC NULLS FIRST], false, 0\n",
      "            :  +- Exchange hashpartitioning(coalesce(a#361, [,,0]), isnull(a#361), coalesce(b#363, [,,0]), isnull(b#363), 200), ENSURE_REQUIREMENTS, [plan_id=5219]\n",
      "            :     +- Project [a#361, b#363]\n",
      "            :        +- SortMergeJoin [_extract_dst#434], [b#363.id], Inner\n",
      "            :           :- Sort [_extract_dst#434 ASC NULLS FIRST], false, 0\n",
      "            :           :  +- Exchange hashpartitioning(_extract_dst#434, 200), ENSURE_REQUIREMENTS, [plan_id=5188]\n",
      "            :           :     +- Project [_extract_dst#434, a#361]\n",
      "            :           :        +- SortMergeJoin [_extract_src#435], [a#361.id], Inner\n",
      "            :           :           :- Sort [_extract_src#435 ASC NULLS FIRST], false, 0\n",
      "            :           :           :  +- Exchange hashpartitioning(_extract_src#435, 200), ENSURE_REQUIREMENTS, [plan_id=5180]\n",
      "            :           :           :     +- Project [dst#7 AS _extract_dst#434, src#6 AS _extract_src#435]\n",
      "            :           :           :        +- Filter (isnotnull(src#6) AND isnotnull(dst#7))\n",
      "            :           :           :           +- Scan ExistingRDD[src#6,dst#7,relationship#8]\n",
      "            :           :           +- Sort [a#361.id ASC NULLS FIRST], false, 0\n",
      "            :           :              +- Exchange hashpartitioning(a#361.id, 200), ENSURE_REQUIREMENTS, [plan_id=5181]\n",
      "            :           :                 +- Project [struct(id, id#0, name, name#1, age, age#2L) AS a#361]\n",
      "            :           :                    +- Filter isnotnull(id#0)\n",
      "            :           :                       +- Scan ExistingRDD[id#0,name#1,age#2L]\n",
      "            :           +- Sort [b#363.id ASC NULLS FIRST], false, 0\n",
      "            :              +- Exchange hashpartitioning(b#363.id, 200), ENSURE_REQUIREMENTS, [plan_id=5189]\n",
      "            :                 +- Project [struct(id, id#373, name, name#374, age, age#375L) AS b#363]\n",
      "            :                    +- Filter isnotnull(id#373)\n",
      "            :                       +- Scan ExistingRDD[id#373,name#374,age#375L]\n",
      "            +- Sort [coalesce(a#410, [,,0]) ASC NULLS FIRST, isnull(a#410) ASC NULLS FIRST, coalesce(b#411, [,,0]) ASC NULLS FIRST, isnull(b#411) ASC NULLS FIRST], false, 0\n",
      "               +- Exchange hashpartitioning(coalesce(a#410, [,,0]), isnull(a#410), coalesce(b#411, [,,0]), isnull(b#411), 200), ENSURE_REQUIREMENTS, [plan_id=5220]\n",
      "                  +- Project [a#410, b#411]\n",
      "                     +- SortMergeJoin [b#411.id, a#410.id], [_extract_src#436, _extract_dst#437], Inner\n",
      "                        :- Sort [b#411.id ASC NULLS FIRST, a#410.id ASC NULLS FIRST], false, 0\n",
      "                        :  +- Exchange hashpartitioning(b#411.id, a#410.id, 200), ENSURE_REQUIREMENTS, [plan_id=5212]\n",
      "                        :     +- Project [a#410, b#411]\n",
      "                        :        +- SortMergeJoin [_extract_dst#439], [b#411.id], Inner\n",
      "                        :           :- Sort [_extract_dst#439 ASC NULLS FIRST], false, 0\n",
      "                        :           :  +- Exchange hashpartitioning(_extract_dst#439, 200), ENSURE_REQUIREMENTS, [plan_id=5203]\n",
      "                        :           :     +- Project [_extract_dst#439, a#410]\n",
      "                        :           :        +- SortMergeJoin [_extract_src#440], [a#410.id], Inner\n",
      "                        :           :           :- Sort [_extract_src#440 ASC NULLS FIRST], false, 0\n",
      "                        :           :           :  +- Exchange hashpartitioning(_extract_src#440, 200), ENSURE_REQUIREMENTS, [plan_id=5195]\n",
      "                        :           :           :     +- Project [dst#402 AS _extract_dst#439, src#401 AS _extract_src#440]\n",
      "                        :           :           :        +- Filter (isnotnull(src#401) AND isnotnull(dst#402))\n",
      "                        :           :           :           +- Scan ExistingRDD[src#401,dst#402,relationship#403]\n",
      "                        :           :           +- Sort [a#410.id ASC NULLS FIRST], false, 0\n",
      "                        :           :              +- Exchange hashpartitioning(a#410.id, 200), ENSURE_REQUIREMENTS, [plan_id=5196]\n",
      "                        :           :                 +- Project [struct(id, id#404, name, name#405, age, age#406L) AS a#410]\n",
      "                        :           :                    +- Filter isnotnull(id#404)\n",
      "                        :           :                       +- Scan ExistingRDD[id#404,name#405,age#406L]\n",
      "                        :           +- Sort [b#411.id ASC NULLS FIRST], false, 0\n",
      "                        :              +- Exchange hashpartitioning(b#411.id, 200), ENSURE_REQUIREMENTS, [plan_id=5204]\n",
      "                        :                 +- Project [struct(id, id#407, name, name#408, age, age#409L) AS b#411]\n",
      "                        :                    +- Filter isnotnull(id#407)\n",
      "                        :                       +- Scan ExistingRDD[id#407,name#408,age#409L]\n",
      "                        +- Sort [_extract_src#436 ASC NULLS FIRST, _extract_dst#437 ASC NULLS FIRST], false, 0\n",
      "                           +- Exchange hashpartitioning(_extract_src#436, _extract_dst#437, 200), ENSURE_REQUIREMENTS, [plan_id=5211]\n",
      "                              +- Project [src#390 AS _extract_src#436, dst#391 AS _extract_dst#437]\n",
      "                                 +- Filter (isnotnull(src#390) AND isnotnull(dst#391))\n",
      "                                    +- Scan ExistingRDD[src#390,dst#391,relationship#392]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oneway.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vm7bOBmfVmfV",
    "outputId": "79bb4a68-7883-4e7f-a8b3-8689e7efc116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+----------------+\n",
      "|               a|               b|               c|\n",
      "+----------------+----------------+----------------+\n",
      "|  {a, Alice, 34}| {e, Esther, 32}|  {f, Fanny, 38}|\n",
      "|{c, Charlie, 37}|    {b, Bob, 36}|{c, Charlie, 37}|\n",
      "|  {g, Gabby, 60}| {e, Esther, 32}|  {f, Fanny, 38}|\n",
      "|  {d, David, 29}|  {a, Alice, 34}|    {b, Bob, 36}|\n",
      "| {e, Esther, 32}|  {f, Fanny, 38}|{c, Charlie, 37}|\n",
      "|  {f, Fanny, 38}|{c, Charlie, 37}|    {b, Bob, 36}|\n",
      "|    {b, Bob, 36}|{c, Charlie, 37}|    {b, Bob, 36}|\n",
      "|  {a, Alice, 34}|    {b, Bob, 36}|{c, Charlie, 37}|\n",
      "|  {g, Gabby, 60}| {e, Esther, 32}|  {d, David, 29}|\n",
      "+----------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Negation\n",
    "oneway = g.find(\"(a)-[]->(b); (b)-[]->(c); !(c)-[]->(a)\")\n",
    "oneway.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ervjsZ75VmfV",
    "outputId": "206daffa-a022-4905-cadd-080f8e79b65e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|             a|\n",
      "+--------------+\n",
      "|{g, Gabby, 60}|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find vertices without incoming edges:\n",
    "single = g.find(\"!()-[]->(a)\")\n",
    "single.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frOvC3XRVmfV",
    "outputId": "e7993f51-7c73-4563-9554-6ca9cdb7e3a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[a#464], functions=[])\n",
      "   +- Exchange hashpartitioning(a#464, 200), ENSURE_REQUIREMENTS, [plan_id=6090]\n",
      "      +- HashAggregate(keys=[a#464], functions=[])\n",
      "         +- Project [struct(id, id#0, name, name#1, age, age#2L) AS a#464]\n",
      "            +- SortMergeJoin [coalesce(struct(id, id#0, name, name#1, age, age#2L), [,,0]), isnull(struct(id, id#0, name, name#1, age, age#2L))], [coalesce(a#478, [,,0]), isnull(a#478)], LeftAnti\n",
      "               :- Sort [coalesce(struct(id, id#0, name, name#1, age, age#2L), [,,0]) ASC NULLS FIRST, isnull(struct(id, id#0, name, name#1, age, age#2L)) ASC NULLS FIRST], false, 0\n",
      "               :  +- Exchange hashpartitioning(coalesce(struct(id, id#0, name, name#1, age, age#2L), [,,0]), isnull(struct(id, id#0, name, name#1, age, age#2L)), 200), ENSURE_REQUIREMENTS, [plan_id=6082]\n",
      "               :     +- Scan ExistingRDD[id#0,name#1,age#2L]\n",
      "               +- Sort [coalesce(a#478, [,,0]) ASC NULLS FIRST, isnull(a#478) ASC NULLS FIRST], false, 0\n",
      "                  +- Exchange hashpartitioning(coalesce(a#478, [,,0]), isnull(a#478), 200), ENSURE_REQUIREMENTS, [plan_id=6083]\n",
      "                     +- Project [a#478]\n",
      "                        +- SortMergeJoin [a#478.id], [_extract_dst#487], Inner\n",
      "                           :- Sort [a#478.id ASC NULLS FIRST], false, 0\n",
      "                           :  +- Exchange hashpartitioning(a#478.id, 200), ENSURE_REQUIREMENTS, [plan_id=6074]\n",
      "                           :     +- Project [struct(id, id#475, name, name#476, age, age#477L) AS a#478]\n",
      "                           :        +- Filter isnotnull(id#475)\n",
      "                           :           +- Scan ExistingRDD[id#475,name#476,age#477L]\n",
      "                           +- Sort [_extract_dst#487 ASC NULLS FIRST], false, 0\n",
      "                              +- Exchange hashpartitioning(_extract_dst#487, 200), ENSURE_REQUIREMENTS, [plan_id=6075]\n",
      "                                 +- Project [dst#7 AS _extract_dst#487]\n",
      "                                    +- Filter isnotnull(dst#7)\n",
      "                                       +- Scan ExistingRDD[src#6,dst#7,relationship#8]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2yNAJf2NVmfV",
    "outputId": "3dab3a33-3839-4be3-afc7-35cba26e0c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+----------------+\n",
      "|           a|             e|               b|\n",
      "+------------+--------------+----------------+\n",
      "|{b, Bob, 36}|{b, c, follow}|{c, Charlie, 37}|\n",
      "+------------+--------------+----------------+\n",
      "\n",
      "+----------------+--------------+----------------+\n",
      "|               a|             e|               b|\n",
      "+----------------+--------------+----------------+\n",
      "|{c, Charlie, 37}|{c, b, follow}|    {b, Bob, 36}|\n",
      "|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 37}|\n",
      "+----------------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More meaningful queries can be expressed by applying filters.\n",
    "# Question: where is this filter applied?\n",
    "#cached in memory=> push all the way down to vextex dataframe\n",
    "#g.find(\"(a)-[e]->(b); (b)-[]->(a)\") multiple joins\n",
    "g.find(\"(a)-[e]->(b); (b)-[]->(a)\").filter(\"b.age > 36\").show()\n",
    "g.find(\"(a)-[e]->(b); (b)-[]->(a)\").filter(\"b.age > 35\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jS8k5vr9VmfW",
    "outputId": "f12644c0-9c3c-46da-cb04-e81506b12f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) Project [a#2584, b#2586]\n",
      "+- *(4) BroadcastHashJoin [b#2586.id, a#2584.id], [__tmp2506060614762666678#2609.src, __tmp2506060614762666678#2609.dst], Inner, BuildRight\n",
      "   :- *(4) Project [a#2584, b#2586]\n",
      "   :  +- *(4) BroadcastHashJoin [__tmp-3851898762290097694#2582.dst], [b#2586.id], Inner, BuildRight\n",
      "   :     :- *(4) BroadcastHashJoin [__tmp-3851898762290097694#2582.src], [a#2584.id], Inner, BuildRight\n",
      "   :     :  :- *(4) Project [struct(src, src#44, dst, dst#45, relationship, relationship#46) AS __tmp-3851898762290097694#2582]\n",
      "   :     :  :  +- InMemoryTableScan [dst#45, relationship#46, src#44]\n",
      "   :     :  :        +- InMemoryRelation [src#44, dst#45, relationship#46], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :     :  :              +- *(1) Scan ExistingRDD[src#44,dst#45,relationship#46]\n",
      "   :     :  +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<id:string,name:string,age:bigint>, false].id)), [id=#1356]\n",
      "   :     :     +- *(1) Project [struct(id, id#38, name, name#39, age, age#40L) AS a#2584]\n",
      "   :     :        +- InMemoryTableScan [age#40L, id#38, name#39]\n",
      "   :     :              +- InMemoryRelation [id#38, name#39, age#40L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :     :                    +- *(1) Scan ExistingRDD[id#38,name#39,age#40L]\n",
      "   :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<id:string,name:string,age:bigint>, false].id)), [id=#1363]\n",
      "   :        +- *(2) Project [struct(id, id#38, name, name#39, age, age#40L) AS b#2586]\n",
      "   :           +- *(2) Filter (isnotnull(age#40L) AND (age#40L > 36))\n",
      "   :              +- InMemoryTableScan [age#40L, id#38, name#39], [isnotnull(age#40L), (age#40L > 36)]\n",
      "   :                    +- InMemoryRelation [id#38, name#39, age#40L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :                          +- *(1) Scan ExistingRDD[id#38,name#39,age#40L]\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, struct<src:string,dst:string,relationship:string>, false].src, input[0, struct<src:string,dst:string,relationship:string>, false].dst)), [id=#1370]\n",
      "      +- *(3) Project [struct(src, src#44, dst, dst#45, relationship, relationship#46) AS __tmp2506060614762666678#2609]\n",
      "         +- InMemoryTableScan [dst#45, relationship#46, src#44]\n",
      "               +- InMemoryRelation [src#44, dst#45, relationship#46], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     +- *(1) Scan ExistingRDD[src#44,dst#45,relationship#46]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g.find(\"(a)-[]->(b); (b)-[]->(a)\").filter(\"b.age > 36\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "cOfsLMsaVmfW",
    "outputId": "de8a4a58-ef58-423c-fb43-da54e3822840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+---------------+--------------+----------------+--------------+----------------+\n",
      "|              a|            e1|              b|            e2|               c|            e3|               d|\n",
      "+---------------+--------------+---------------+--------------+----------------+--------------+----------------+\n",
      "| {g, Gabby, 60}|{g, e, follow}|{e, Esther, 32}|{e, d, friend}|  {d, David, 29}|{d, a, friend}|  {a, Alice, 34}|\n",
      "|{e, Esther, 32}|{e, d, friend}| {d, David, 29}|{d, a, friend}|  {a, Alice, 34}|{a, b, friend}|    {b, Bob, 36}|\n",
      "|{e, Esther, 32}|{e, f, follow}| {f, Fanny, 38}|{f, c, follow}|{c, Charlie, 37}|{c, b, follow}|    {b, Bob, 36}|\n",
      "| {d, David, 29}|{d, a, friend}| {a, Alice, 34}|{a, b, friend}|    {b, Bob, 36}|{b, c, follow}|{c, Charlie, 37}|\n",
      "| {a, Alice, 34}|{a, e, friend}|{e, Esther, 32}|{e, f, follow}|  {f, Fanny, 38}|{f, c, follow}|{c, Charlie, 37}|\n",
      "| {g, Gabby, 60}|{g, e, follow}|{e, Esther, 32}|{e, f, follow}|  {f, Fanny, 38}|{f, c, follow}|{c, Charlie, 37}|\n",
      "| {d, David, 29}|{d, a, friend}| {a, Alice, 34}|{a, e, friend}| {e, Esther, 32}|{e, f, follow}|  {f, Fanny, 38}|\n",
      "+---------------+--------------+---------------+--------------+----------------+--------------+----------------+\n",
      "\n",
      "+---------------+---------------+---------------+----------------+\n",
      "|              a|              b|              c|               d|\n",
      "+---------------+---------------+---------------+----------------+\n",
      "| {g, Gabby, 60}|{e, Esther, 32}| {d, David, 29}|  {a, Alice, 34}|\n",
      "|{e, Esther, 32}| {d, David, 29}| {a, Alice, 34}|    {b, Bob, 36}|\n",
      "| {d, David, 29}| {a, Alice, 34}|   {b, Bob, 36}|{c, Charlie, 37}|\n",
      "| {d, David, 29}| {a, Alice, 34}|{e, Esther, 32}|  {f, Fanny, 38}|\n",
      "+---------------+---------------+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find chains of 4 vertices such that at least 2 of the 3 edges are \"friend\" relationships.\n",
    "# The when function is similar to the CASE WHEN in SQL\n",
    "\n",
    "chain4 = g.find(\"(a)-[e1]->(b); (b)-[e2]->(c); (c)-[e3]->(d)\").where('a!=d AND a!=c AND b!=d')#want 4 unqiue users\n",
    "chain4.show()\n",
    "friendTo1 = lambda e: when(e['relationship'] == 'friend', 1).otherwise(0)#check whether relationship is friend or follow\n",
    "#column pruning, \"*\", optimer will figure out to print which columns\n",
    "chain4.select('*',friendTo1(chain4['e1']).alias('f1'), \\\n",
    "                  friendTo1(chain4['e2']).alias('f2'), \\\n",
    "                  friendTo1(chain4['e3']).alias('f3')) \\\n",
    "      .where('f1 + f2 + f3 >= 2').select('a', 'b', 'c', 'd').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErH3isboVmfW"
   },
   "source": [
    "### Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebS8lsCQVmfW",
    "outputId": "f9341248-78b3-4f4a-c8c0-6f1f73c346fd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+\n",
      "| id|  name|age|\n",
      "+---+------+---+\n",
      "|  e|Esther| 32|\n",
      "|  b|   Bob| 36|\n",
      "|  a| Alice| 34|\n",
      "+---+------+---+\n",
      "\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  a|  e|      friend|\n",
      "|  a|  b|      friend|\n",
      "+---+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select subgraph of users older than 30, and relationships of type \"friend\".\n",
    "# Drop isolated vertices (users) which are not contained in any edges (relationships).\n",
    "\n",
    "g1 = g.filterVertices(\"age > 30\").filterEdges(\"relationship = 'friend'\")\\\n",
    "      .dropIsolatedVertices()# 22-friend-31(nonsense to have an edge with a non satis node 22)\n",
    "\n",
    "g1.vertices.show()\n",
    "g1.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJFFUqE9VmfW",
    "outputId": "f1816621-f015-4590-8c8f-14433f19a69a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+----------------+\n",
      "|              a|             e|               b|\n",
      "+---------------+--------------+----------------+\n",
      "|[e, Esther, 32]|[e, f, follow]|  [f, Fanny, 38]|\n",
      "|   [b, Bob, 36]|[b, c, follow]|[c, Charlie, 37]|\n",
      "+---------------+--------------+----------------+\n",
      "\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  e|  f|      follow|\n",
      "|  b|  c|      follow|\n",
      "+---+---+------------+\n",
      "\n",
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  f|  Fanny| 38|\n",
      "|  e| Esther| 32|\n",
      "|  c|Charlie| 37|\n",
      "|  b|    Bob| 36|\n",
      "+---+-------+---+\n",
      "\n",
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  e|  f|      follow|\n",
      "|  b|  c|      follow|\n",
      "+---+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select subgraph based on edges \"e\" of type \"follow\"\n",
    "# pointing from a younger user \"a\" to an older user \"b\".\n",
    "\n",
    "paths = g.find(\"(a)-[e]->(b)\")\\\n",
    "  .filter(\"e.relationship = 'follow'\")\\\n",
    "  .filter(\"a.age < b.age\")\n",
    "\n",
    "paths.show()\n",
    "# \"paths\" contains vertex info. Extract the edges.\n",
    "\n",
    "e2 = paths.select(\"e.*\")\n",
    "e2.show()\n",
    "\n",
    "# Construct the subgraph\n",
    "g2 = GraphFrame(g.vertices, e2).dropIsolatedVertices()\n",
    "\n",
    "g2.vertices.show()\n",
    "g2.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "|Fanny|\n",
      "|  Bob|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find all people who follow Charlie.\n",
    "g.find(\"(a)-[e]->(b)\").filter(\"e.relationship = 'follow' and b.name = 'Charlie'\").select(\"a.name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXEXcrDbVmfX"
   },
   "source": [
    "### BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8m0TdaJVmfX"
   },
   "outputs": [],
   "source": [
    "# Starting vertex is 'a'\n",
    "# bfs is suitable for graph with short diameter; \n",
    "layers = [g.vertices.select('id').where(\"id = 'a'\")]#store different layers: list of lists\n",
    "visited =  layers[0]\n",
    "\n",
    "while layers[-1].count() > 0:#layers[-1]: current layer\n",
    "    # From the current layer, get all the one-hop neighbors\n",
    "    d1 = layers[-1].join(g.edges, layers[-1]['id'] == g.edges['src'])\n",
    "    # Rename the column as 'id', and remove visited verices and duplicates\n",
    "    d2 = d1.select(d1['dst'].alias('id')) \\\n",
    "           .subtract(visited).distinct().cache()# may conatin multiple duplicates when joining\n",
    "    layers += [d2]\n",
    "    visited = visited.union(layers[-1]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2NkBUIXVmfX",
    "outputId": "d73677d9-84b3-49bf-fed2-c61507d42598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  a|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dTsLYHjVmfX",
    "outputId": "62f322cb-de02-405c-a79f-95734abeaf98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  e|\n",
      "|  b|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers[1].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRM6npv8VmfX",
    "outputId": "0147a75e-f62a-4d35-ecb7-fa3593ca8982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  f|\n",
      "|  d|\n",
      "|  c|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers[2].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DsjcSOrVmfY",
    "outputId": "e5b5e632-e60d-41f0-cca4-6dc97ea95501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers[3].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-oBBQrkVmfY",
    "outputId": "e5ef8861-d36e-47ea-d611-35df50bac798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+---------------+--------------+----------------+\n",
      "|          from|            e0|             v1|            e1|              to|\n",
      "+--------------+--------------+---------------+--------------+----------------+\n",
      "|{a, Alice, 34}|{a, b, friend}|   {b, Bob, 36}|{b, c, follow}|{c, Charlie, 37}|\n",
      "|{a, Alice, 34}|{a, e, friend}|{e, Esther, 32}|{e, f, follow}|  {f, Fanny, 38}|\n",
      "+--------------+--------------+---------------+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GraphFrames provides own BFS:\n",
    "\n",
    "paths = g.bfs(\"id = 'a'\", \"age > 36\")\n",
    "paths.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRTTNCdNVmfY"
   },
   "source": [
    "### List Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6NkXAyYVmfY",
    "outputId": "ec1850fe-6163-4812-9967-573e2cfb8128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|  d|\n",
      "+---+---+\n",
      "|  0|  1|\n",
      "|  1|  1|\n",
      "|  3|  1|\n",
      "|  4|  1|\n",
      "|  5|  0|\n",
      "|  6|  1|\n",
      "| -1|  0|\n",
      "+---+---+\n",
      "\n",
      "+---+---+\n",
      "|src|dst|\n",
      "+---+---+\n",
      "|  0|  5|\n",
      "|  1|  0|\n",
      "|  3|  4|\n",
      "|  4|  6|\n",
      "|  5| -1|\n",
      "|  6|  1|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -1 denotes end of list\n",
    "data = [(0, 5), (1, 0), (3, 4), (4, 6), (5, -1), (6,1)]# 3 is the starting node (5, -1) is the last node\n",
    "e = spark.createDataFrame(data, ['src', 'dst'])\n",
    "v = e.select(col('src').alias('id'), when(e.dst == -1, 0).otherwise(1).alias('d'))#initialization of link ranking(d represent distance)\n",
    "v1 = spark.createDataFrame([(-1, 0)], ['id', 'd'])\n",
    "v = v.union(v1)\n",
    "v.show()\n",
    "e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMIAmBaUVmfY",
    "outputId": "edc4bd6e-7e8c-4d8f-be91-70cb054414d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|src|dst|\n",
      "+---+---+\n",
      "|  6|  0|\n",
      "|  3|  6|\n",
      "|  1|  5|\n",
      "|  4|  1|\n",
      "|  0| -1|\n",
      "|  5| -1|\n",
      "+---+---+\n",
      "\n",
      "+---+---+\n",
      "|src|dst|\n",
      "+---+---+\n",
      "|  3|  0|\n",
      "|  4|  5|\n",
      "|  6| -1|\n",
      "|  1| -1|\n",
      "|  0| -1|\n",
      "|  5| -1|\n",
      "+---+---+\n",
      "\n",
      "+---+---+\n",
      "|src|dst|\n",
      "+---+---+\n",
      "|  3| -1|\n",
      "|  4| -1|\n",
      "|  1| -1|\n",
      "|  6| -1|\n",
      "|  0| -1|\n",
      "|  5| -1|\n",
      "+---+---+\n",
      "\n",
      "+---+---+\n",
      "| id|  d|\n",
      "+---+---+\n",
      "|  0|  1|\n",
      "|  1|  2|\n",
      "|  3|  5|\n",
      "|  4|  4|\n",
      "|  5|  0|\n",
      "|  6|  3|\n",
      "| -1|  0|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while e.filter('dst != -1').count() > 0:\n",
    "    g = GraphFrame(v, e)\n",
    "    g.cache()\n",
    "    v = g.triplets.select(col('src.id').alias('id'), \n",
    "                          (col('src.d') + col('dst.d')).alias('d')) \\#\n",
    "         .union(v1)\n",
    "    e = g.find('(a)-[]->(b); (b)-[]->(c)') \\# find node.next.next;(add -1 0, otherwise the last node cannot be find though motif finding)\n",
    "         .select(col('a.id').alias('src'), col('c.id').alias('dst')) \\\n",
    "         .union(e.filter('dst = -1'))\n",
    "    e.show()\n",
    "v.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piVWCYWZVmfY"
   },
   "source": [
    "### Message passing via AggregateMessages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2JJTWL7VmfZ",
    "outputId": "b04945f0-f416-4315-9c23-e5b6d8e36423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|summedAges|\n",
      "+---+----------+\n",
      "|  f|        32|\n",
      "|  e|        94|\n",
      "|  d|        32|\n",
      "|  c|        74|\n",
      "|  b|        71|\n",
      "|  a|        29|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce, col, lit, sum, when, min, max\n",
    "from graphframes.lib import AggregateMessages as AM\n",
    "\n",
    "# AggregateMessages has the following members: src, dst, edge, msg\n",
    "# For each user, sum the ages of the adjacent users.\n",
    "agg = g.aggregateMessages(\n",
    "    sum(AM.msg).alias(\"summedAges\"),\n",
    "    #sendToSrc = AM.dst['age'],\n",
    "    sendToDst = AM.src['age'])\n",
    "agg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "ww3AB4kMVmfZ"
   },
   "source": [
    "### The Pregel Model for Graph Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lptcZZXaVmfZ",
    "outputId": "1a47f963-7259-4c99-8521-7dfb64864b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------------------+\n",
      "| id|outDegree|               rank|\n",
      "+---+---------+-------------------+\n",
      "|  a|        2|    0.4758149609375|\n",
      "|  b|        1| 2.2680220312499997|\n",
      "|  c|        1|  2.780783203124999|\n",
      "|  f|        1|0.41104330078124995|\n",
      "|  e|        2| 0.5032932031249999|\n",
      "|  d|        1|0.41104330078124995|\n",
      "|  g|        1|               0.15|\n",
      "+---+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pagerank in the Pregel model \n",
    "\n",
    "from pyspark.sql.functions import coalesce, col, lit, sum, when, min\n",
    "from graphframes.lib import Pregel\n",
    "\n",
    "# Need to set up a directory for Pregel computation\n",
    "sc.setCheckpointDir(\"checkpoint\")\n",
    "\n",
    "'''\n",
    "Use builder pattern to describe the operations.\n",
    "Call run() to start a run. It returns a DataFrame of vertices from the last iteration.\n",
    "\n",
    "When a run starts, it expands the vertices DataFrame using column expressions \n",
    "defined by withVertexColumn(). Those additional vertex properties can be \n",
    "changed during Pregel iterations. In each Pregel iteration, there are three \n",
    "phases:\n",
    "\n",
    "* Given each edge triplet, generate messages and specify target vertices to \n",
    "  send, described by sendMsgToDst() and sendMsgToSrc().\n",
    "* Aggregate messages by target vertex IDs, described by aggMsgs().\n",
    "* Update additional vertex properties based on aggregated messages and states \n",
    "  from previous iteration, described by withVertexColumn().\n",
    "'''\n",
    "v = g.outDegrees\n",
    "g = GraphFrame(v,e)\n",
    "ranks = g.pregel \\\n",
    "        .setMaxIter(5) \\\n",
    "        .sendMsgToDst(Pregel.src(\"rank\") / Pregel.src(\"outDegree\")) \\# can also sendMsgToSrc\n",
    "        .aggMsgs(sum(Pregel.msg())) \\\n",
    "        .withVertexColumn(\"rank\", lit(1.0), \\#turn constant into a column of constant\n",
    "            coalesce(Pregel.msg(), lit(0.0)) * lit(0.85) + lit(0.15)) \\# no message, no computation 0*anything = 0\n",
    "        .run()\n",
    "ranks.show()\n",
    "\n",
    "# pyspark.sql.functions.coalesce(*cols): Returns the first column that is not null.\n",
    "\n",
    "# Not to be confused with spark.sql.coalesce(numPartitions)# merge partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfN2uWG_VmfZ",
    "outputId": "06f26126-ae18-4bd3-9497-6f96cd6af4a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----+------+\n",
      "| id|outDegree|    d|active|\n",
      "+---+---------+-----+------+\n",
      "|  a|        2|    0| false|\n",
      "|  b|        1|    1| false|\n",
      "|  c|        1|    2| false|\n",
      "|  f|        1|    2| false|\n",
      "|  e|        2|    1| false|\n",
      "|  d|        1|    2| false|\n",
      "|  g|        1|99999| false|\n",
      "+---+---------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BFS in the Pregel model\n",
    "\n",
    "g = GraphFrame(v,e)\n",
    "\n",
    "dist = g.pregel \\\n",
    "        .sendMsgToDst(when(Pregel.src('active'), Pregel.src('d') + 1)) \\\n",
    "        .aggMsgs(min(Pregel.msg())) \\\n",
    "        .withVertexColumn('d', when(v['id'] == 'a', 0).otherwise(99999), \\\n",
    "            when(Pregel.msg() < col('d'), Pregel.msg()).otherwise(col('d'))) \\#d represent distance\n",
    "        .withVertexColumn('active', when(v['id'] == 'a', True).otherwise(False), \\\n",
    "            when(Pregel.msg() < col('d'), True).otherwise(False)) \\#active or not\n",
    "        .run()\n",
    "dist.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
